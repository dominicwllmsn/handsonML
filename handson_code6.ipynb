{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T22:09:45.249484Z",
     "start_time": "2020-08-01T22:09:45.221271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Like SVMs, Decision Trees are versatile ML algorithms which can perform both regression and classification, as well as \n",
    "#multioutput tasks. They are powerful and capable of fitting complex datasets (e.g. overfitted housing dataset in chpt 2).\n",
    "#Here we have a classification example with the iris dataset using DecisionTreeClassifier:\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, 2:] #petal length, petal width\n",
    "y = iris.target\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
    "tree_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T23:44:50.579516Z",
     "start_time": "2020-08-01T23:44:50.575931Z"
    }
   },
   "outputs": [],
   "source": [
    "#To visualize the trained Decision Tree, use export_graphvix() to output a graph definition file called iris_tree.dot\n",
    "from sklearn.tree import export_graphviz\n",
    "import os\n",
    "\n",
    "def image_path(file):\n",
    "    path = os.path.join(os.getcwd(), file)\n",
    "    return path\n",
    "\n",
    "export_graphviz(tree_clf, out_file=image_path('iris_tree.dot'),\n",
    "               feature_names=iris.feature_names[2:],\n",
    "               class_names=iris.target_names,\n",
    "               rounded=True,\n",
    "               filled=True)\n",
    "\n",
    "#The dot command-line tool from the Graphviz package can then convert the .dot file to a pdf or png, via:\n",
    "# dot -Tpng iris_tree.dot -o iris_tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DT](iris_tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T22:41:52.699384Z",
     "start_time": "2020-08-01T22:41:52.696432Z"
    }
   },
   "outputs": [],
   "source": [
    "#To see how the tree makes predictions: to classify an unknown iris, start at the root node (depth 0), it asks if the \n",
    "#petal length <= 2.45cm. If true, move to the root's left child node (depth 1, left). In this case, it is a leaf node since\n",
    "#it does not itself have any child nodes, so does not ask any questions. Simply look at the class for that node - the \n",
    "#Decision Tree predicts that class=setosa.\n",
    "#If another flower has petal length > 2.45cm, move to the root's right child node (depth 1, right), which is not a leaf \n",
    "#node, so it asks another question - if the petal width <= 1.75cm. If it is, class=versicolor (depth 2, left), else then\n",
    "#class=viginica (depth 2, right).\n",
    "\n",
    "#Each node's samples attribute counts how many training instances it applies to. The value attribute gives the number\n",
    "#of training instances of each class that this node applies to - the depth-2 right node applies to 0 setosa, 1 versicolor\n",
    "#and 45 virginica. The gini attribute measures its impurity - a node is pure (gini=0) if all training instances it applies\n",
    "#to belong to the same class. The gini score of the ith node is G_i = 1 - Σ(p_i_k)^2 where p_i_k is the ratio of class k\n",
    "#instances among the training instances of the ith node. The depth-2 left node has G = 1-(0/54)^2 - (49/54)^2 - (5/54)^2.\n",
    "\n",
    "#Since max_depth=2 above, the Decision Tree stops at two decision boundaries in parameter space - adding greater depth\n",
    "#will further fragment the impure area (the pure area, containing only iris setosa, cannot be split any further).\n",
    "\n",
    "#N.B. Decision Trees are intuitive, and their decisions are easy to interpret. Such models are often called white box \n",
    "#models. In contrast, as we will see, Random Forests or neural networks are generally considered black box models. They \n",
    "#make great predictions, and you can easily check the calculations that they performed to make these predictions; \n",
    "#nevertheless, it is usually hard to explain in simple terms why the predictions were made. For example, if a neural \n",
    "#network says that a particular person appears on a picture, it is hard to know what contributed to this prediction: did \n",
    "#the model recognize that person’s eyes? Their mouth? Their nose? Their shoes? Or even the couch that they were sitting \n",
    "#on? Conversely, Decision Trees provide nice, simple classification rules that can even be applied manually if need be \n",
    "#(e.g., for flower classification).\n",
    "#Another quality of Decision Trees is that they require very little data preparation (no feature scaling or centering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T22:47:34.151628Z",
     "start_time": "2020-08-01T22:47:34.148745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.90740741, 0.09259259]]), array([1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision Trees can also estimate the probability that an instance belongs to a particular class k - it traverses the\n",
    "#tree to find the leaf node for the instance, then returns the ratio of training instance of class k in this node. For \n",
    "#example, with a flower 5cm and 1.5cm wide, it corresponds to the depth-2 left node, so the Decision Tree will output\n",
    "#the following probabilities: 0% (0/54) for setosa, 90.7% (49/54) for versicolor and 9.3% (5/54) for virginica. If asked\n",
    "#to predict a class, it will output class 1 (Iris versicolor) as it has the highest probability.\n",
    "\n",
    "tree_clf.predict_proba([[5, 1.5]]), tree_clf.predict([[5, 1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T23:24:39.031564Z",
     "start_time": "2020-08-01T23:24:39.029646Z"
    }
   },
   "outputs": [],
   "source": [
    "#Scikit-Learn uses the CART algorithm, producing only binary trees (nonleaf nodes always have two children, so questions\n",
    "#only with yes/no answers). Other algorithms, such as ID3, can produce DTs with nodes that have more than two children.\n",
    "#CART stands for Classification and Regression Tree. It splits the training set into two subsets using a single feature k\n",
    "#and a threshold t_k (e.g. petal length <= 2.45cm). It chooses k and t_k by searching for the pair (k, t_k) that produces\n",
    "#the purest subsets (weighted by their size). For left and right subsets, CART minimises the cost function:\n",
    "# J(k, t_k) = (m_left/m)*G_left + (m_right/m)*G_right. After splitting the training set into two, it splits the subsets\n",
    "#using the same logic, then the sub-subsets etc. recursively, stopping at the set maximum depth (via the max_depth \n",
    "#hyperparameter), or if it cannot find a split that will reduce impurity. Additional stopping conditions are controlled by\n",
    "#the hyperparameters min_samples_split, min_samples_leaf, min_weight_fraction_leaf, and max_left_nodes.\n",
    "\n",
    "#Note that CART is a greedy algorithm: it greedily searches for an optimum split at the top level, then repeats at each\n",
    "#subsequent level - it does not check whether or not the split will lead to the lowest possible impurity several levels\n",
    "#down the tree. Greedy algorithms tend to produce solutions that are reasonably good but not guaranteed to be optimal.\n",
    "#Finding an optimal tree is NP-complete: it requires O(exp(m)) time, therefore intractable even more small training sets - \n",
    "#hence we settle for 'reasonably good'.\n",
    "#With respect to the computational complexity of predictions, making one required traversing the Decision Tree from the \n",
    "#root to a leaf. In general Decision Trees are approximately balanced, so traversing a tree requires traversing around\n",
    "#O(log_2(m)) nodes. As each node requires checking the value of one feature, total prediction complexity is O(log_2(m)),\n",
    "#independant of n - hence prediction is fast even with large training sets. \n",
    "#The training algorithm compares all n features (or less if max_features is set) on all samples at each node, resulting in\n",
    "#complexity O(n * mlog_2(m)). For small (1000s) datasets, sklearn can speed up training by presorting the data (set \n",
    "#presort=True), but doing so for larger datasets slows training considerably.\n",
    "\n",
    "#By default, the Gini impurity measure is used, but the entropy impurity measure may be selected instead by setting the\n",
    "#hyperparameter criterion='entropy'. In thermodynamics, entropy tends to zero when the molecules are still and well\n",
    "#ordered, while in Shannon's information theory it measures the average information content of a message (a reduction of\n",
    "#entropy is often termed an information gain) - entropy is zero when all messages are identical. In ML entropy is often\n",
    "#used as an inpurity measure - a set has zero entropy when it contains instances of only one class. It is found by:\n",
    "# H_i = − Σ p_i_k*log_2(p_i_k), where we sum from k=1 to n and p_i_k != 0. The above depth-2 left node has H = 0.445.\n",
    "#Most of the time, choosing Gini impurity or entropy makes little difference (they lead to similar trees). Gini impurity\n",
    "#is faster, so is a good default. When they do differ, Gini tends to isolate the most frequent class in its own branch \n",
    "#while entropy produces slightly more balanced trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T23:36:28.708744Z",
     "start_time": "2020-08-01T23:36:28.706894Z"
    }
   },
   "outputs": [],
   "source": [
    "#Decision Trees make very few assumptions about the training data (as opposed to linear models, which assume that the data \n",
    "#is linear, for example). If left unconstrained, the tree structure will adapt itself to the training data, fitting it very\n",
    "#closely—indeed, most likely overfitting it. Such a model is often called a nonparametric model, not because it does not \n",
    "#have any parameters (it often has a lot) but because the number of parameters is not determined prior to training, so the\n",
    "#model structure is free to stick closely to the data. In contrast, a parametric model, such as a linear model, has a \n",
    "#predetermined number of parameters, so its degree of freedom is limited, reducing the risk of overfitting (but increasing\n",
    "#the risk of underfitting).\n",
    "\n",
    "#To avoid overfitting the training data, you need to restrict the Decision Tree’s freedom during training regularization. \n",
    "#The regularization hyperparameters depend on the algorithm used, but generally you can at least restrict the max_depth\n",
    "#hyperparameter (the default value is None, which means unlimited). The DecisionTreeClassifier class has a few other \n",
    "#parameters that similarly restrict the shape of the Decision Tree: (1) min_samples_split (the minimum number of samples a \n",
    "#node must have before it can be split), (2) min_samples_leaf (the minimum number of samples a leaf node must have), \n",
    "#(3) min_weight_fraction_leaf (same as min_samples_leaf but expressed as a fraction of the total number of weighted \n",
    "#instances), (4) max_leaf_nodes (the maximum number of leaf nodes), and (5) max_features (the maximum number of features \n",
    "#that are evaluated for splitting at each node). Increasing min_* hyperparameters or reducing max_* hyperparameters will\n",
    "#regularize the model. For example increasing min_samples_leaf to 4 could reduce overfitting by preventing leaf nodes\n",
    "#which only cover a small number of training instances correctly.\n",
    "\n",
    "#Other algorithms work by first training the Decision Tree without restrictions, then pruning (deleting) unnecessary nodes.\n",
    "#A node whose children are all leaf nodes is considered unnecessary if the purity improvement it provides is not \n",
    "#statistically significant. Standard statistical tests, such as the χ2 test (chi-squared test), are used to estimate the\n",
    "#probability that the improvement is purely the result of chance (which is called the null hypothesis). If this probability\n",
    "#(the p-value), is higher than a given threshold (typically 5%, controlled by a hyperparameter), then the node is \n",
    "#considered unnecessary and its children are deleted. The pruning continues until all unnecessary nodes have been pruned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T00:17:41.293475Z",
     "start_time": "2020-08-02T00:17:41.213206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 15\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Decision Trees can also perform regression using the DecisionTreeRegressor class:\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "m = 200\n",
    "X = 2*np.random.rand(m, 1) - 1\n",
    "y = 2*X**2  + np.random.randn(m, 1)/3\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X, y)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=4)\n",
    "tree_reg2.fit(X, y)\n",
    "\n",
    "print(tree_reg1.get_n_leaves(), tree_reg2.get_n_leaves())\n",
    "\n",
    "X_range = np.linspace(-1, 1, 500).reshape(-1 , 1)\n",
    "y_pred1 = tree_reg1.predict(X_range)\n",
    "y_pred2 = tree_reg2.predict(X_range)\n",
    "plt.plot(X_range, y_pred1, 'r-')\n",
    "plt.plot(X_range, y_pred2, 'g-')\n",
    "plt.plot(X, y, 'b.')\n",
    "plt.show()\n",
    "\n",
    "export_graphviz(tree_reg1, out_file=image_path('reg_tree2.dot'),\n",
    "               feature_names=['x1'],\n",
    "               rounded=True,\n",
    "               filled=True)\n",
    "\n",
    "#The dot command-line tool from the Graphviz package can then convert the .dot file to a pdf or png, via:\n",
    "# dot -Tpng reg_tree.dot -o reg_tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-01T23:47:01.129499Z",
     "start_time": "2020-08-01T23:47:00.999908Z"
    }
   },
   "source": [
    "![DT_reg](reg_tree2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The tree is similar to the one for classification, except that instead of predicting a class in each node, it predicts a\n",
    "#value. The bottom rightmost node predicts a value of 1.246. This prediction is the average target value of the 46 training\n",
    "#instances associated with this leaf node, and it results in a mean squared error of 1.246 over these 46 instances.\n",
    "#Note how the predicted value for each region is always the average target value of the instances in that region - the \n",
    "#algorithm splits each region in a way that makes most training instances as close as possible to that predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T00:03:58.081083Z",
     "start_time": "2020-08-02T00:03:58.005649Z"
    }
   },
   "outputs": [],
   "source": [
    "#The CART algorithm works similar to as it did with classification, except that instead of trying to split the training\n",
    "#set in a way that minimizes impurity, it now tries to split in a way that minimizes MSE:\n",
    "# J(k, t_k) = (m_left/m)*MSE_left + (m_right/m)*MSE_right where MSE_node = Σ (y_hat_node - y^(i))^2, where y_hat is the\n",
    "#average value of all the instances in the node, and the summation is over all the instances in the node.\n",
    "\n",
    "#As with classification Decision Trees, those for regression are also prone to overfitting. Regularizing is often required\n",
    "#using the previously listed min_* and max_* hyperparameters, such as min_samples_leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Trees have a lot going for them: they are simple to understand and interpret, easy to use, versatile, and \n",
    "#powerful. However, they do have a few limitations. First, as you may have noticed, Decision Trees love orthogonal \n",
    "#decision boundaries (all splits are perpendicular to an axis), which makes them sensitive to training set rotation.\n",
    "#For example, if you have a linearly separable dataset, such that all instances where x1 <= 0 are class 0 and class 1 if \n",
    "#x1 > 0, a Decision Tree can split it easily. Meanwhile this dataset rotated 45 degrees makes the decision boundary \n",
    "#unnecessaryily convoluted. Although both Decision Trees may fit the training data perfectly, the convoluted model is\n",
    "#unlikely to generalize well. One way to limit this is with Principal Component Analysis (PCA) which often results in a \n",
    "#better orientation of the training data.\n",
    "\n",
    "#More generally, the main issue with Decision Trees is that they are very sensitive to small variations in the training \n",
    "#data. For example, if you just remove the widest Iris versicolor from the iris training set (the one with petals 4.8 cm \n",
    "#long and 1.8 cm wide) and train a new Decision Tree, you may get a completely different set of (feature, threshold) pairs\n",
    "#that the Decision Tree decides to use to split up the data. Actually, since the training algorithm used by sklearn is\n",
    "#stochastic (it randomly selects the set of features to evaluate at each node), you may get very different models even on\n",
    "#the same training data (unless you set the random_state hyperparameter).\n",
    "#Random Forests can limit this instability by averaging predictions over many trees - see the next section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
